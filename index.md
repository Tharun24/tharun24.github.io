---
layout: page
published: true
---

I am a 4th year PhD student in the Electrical and Computer Engineering Department, Rice University. I work with [Prof. Anshumali Shrivastava](https://www.cs.rice.edu/~as143/) in the [RUSHLAB](https://rushlab.blogs.rice.edu/). My primary research area is Extreme Scale Deep Learning using Randomized Hashing methods.

I previously interned as an *Applied Scientist* at **Amazon Search**, Palo Alto from *May 2018 - Aug 2019*. I worked on a myriad of problems like query-category prediction, super-fast reformulation for zero result queries, query to product prediction and fast approximate nearest neighbor search. My paper **Simultaneous Matching and Ranking as end-to-end Deep Classification: A Case study of Information Retrieval with 50M Documents** in conjunction with Amazon got published at **NeurIPS 2019**. 

I received my Bachelor of Technology (B.Tech.) in Electrical Engineering (2011-2015) from [Indian Institute of Technology, Bombay](http://www.iitb.ac.in).

Here is my [`resume`](https://tharun24.github.io/Resume.pdf).

### News:
* I wrote an article about life and PhD at Rice University for Insight IITB. [`link`](https://www.insightiitb.org/rice-university-tharun-medini-univ-series/)
* I gave a talk about my work *Imitate like a Baby:The Key to Efficient Exploration in Deep Reinforcement Learning* at BioScience Research Collaborative (BRC) in Rice Data Science Conference on Oct 14th. [`video`](https://www.youtube.com/watch?v=BzCE1tA9QeI&list=PLcsG4X8Zn_UD-U-uOKeq6SwoIJTcf_mbd&index=15)   [`pdf`](https://tharun24.github.io/AAAI_Imitation.pdf)
* I'll be giving an talk on 'Imitation Learning' at Schlumberger, Katy, TX on Nov 19th.  
* We'll present our paper *Simultaneous Matching and Ranking as end-to-end Deep Classification: A Case study of Information Retrieval with 50M Documents* at **NeurIPS 2019**. [`pdf`](https://arxiv.org/pdf/1910.13830.pdf) [`poster`](https://tharun24.github.io/Tharun_Medini_Poster.pdf)
* We'll present __4 papers__ in __NeurIPS 2019 workshops__. Please refer to [Publications](publications.md) for a list of all papers.  
* We built a system __SLIDE__ which blends smart randomized algorithm, multi-core parallelism and workload optimization to train fully connected neural networks __3.5x faster__ on __CPU__ than NVIDIA Tesla __V-100 GPU__ for large output space problems (extreme classification). Our work featured in __IEEE Spectrum Journal Watch__ ([Hash Your Way To a Better Neural Network](https://spectrum.ieee.org/tech-talk/computing/hardware/algorithms-and-hardware-for-deep-learning)). The article was authored by [David Schneider](https://spectrum.ieee.org/author/schneider-david).
