---
layout: page
published: true
---

I am a 4th year PhD student in the Electrical and Computer Engineering Department, Rice University. I work with [Prof. Anshumali Shrivastava](https://www.cs.rice.edu/~as143/) in the [RUSHLAB](https://rushlab.blogs.rice.edu/). My primary research area is Extreme Scale Deep Learning using Randomized Hashing methods.

I previously interned as an *Applied Scientist* at **Amazon Search**, Palo Alto from *May 2018 - Aug 2019*. I worked on a myriad of problems like query-category prediction, super-fast reformulation for zero result queries, query to product prediction and fast approximate nearest neighbor search. My paper **Extreme Classification in Log Memory using Count-Min Sketch: A Case Study of Amazon Search with 50M Products** in conjunction with Amazon got published at **NeurIPS 2019**. 

I received my Bachelor of Technology (B.Tech.) in Electrical Engineering (2011-2015) from [Indian Institute of Technology, Bombay](http://www.iitb.ac.in).

Here is my [`resume`](https://tharun24.github.io/Resume.pdf).

### Updates:
* Received American Society of Indian Engineers (ASIE) scholarship for 2019.
* I wrote an article about life and PhD at Rice University for Insight IITB. [`link`](https://www.insightiitb.org/rice-university-tharun-medini-univ-series/)
* We'll present our paper *Extreme Classification in Log Memory using Count-Min Sketch: A Case Study of Amazon Search with 50M Products* at **NeurIPS 2019**. [`pdf`](https://papers.nips.cc/paper/9482-extreme-classification-in-log-memory-using-count-min-sketch-a-case-study-of-amazon-search-with-50m-products.pdf) [`poster`](https://tharun24.github.io/miscellaneous/MACH_Poster.pdf)  [`video`](https://www.youtube.com/watch?v=zHXy-AlzSxQ)
* We'll present __4 papers__ in __NeurIPS 2019 workshops__. Please refer to [Publications](publications.md) for a list of all papers.  
* We built a system __SLIDE__ which blends smart randomized algorithm, multi-core parallelism and workload optimization to train fully connected neural networks __3.5x faster__ on __CPU__ than NVIDIA Tesla __V-100 GPU__ for large output space problems (extreme classification) [`pdf`](https://arxiv.org/pdf/1903.03129.pdf) [`package`](https://github.com/keroro824/HashingDeepLearning).

### In the News:
* Popular tech media [`ARS Technica`](https://arstechnica.com/) wrote a great article [`Deep Learning breakthrough made by Rice University scientists`](https://arstechnica.com/gadgets/2019/12/mach-ai-training-linear-cost-exponential-gain/) about my NeurIPS paper.
* [`TechXplore`](https://techxplore.com/) published the Rice News [`article`](http://news.rice.edu/2019/12/09/rice-amazon-report-breakthrough-in-distributed-deep-learning-2/) about my NeurIPS 2019 paper.  
* My research on *Extreme Scale Search using Count-Min Sketch* featured in __Rice News__ ([Rice, Amazon report breakthrough in ‘distributed deep learning’](http://news.rice.edu/2019/12/09/rice-amazon-report-breakthrough-in-distributed-deep-learning-2/)). The article was authored by Jade Boyd.
* [`IEEE Spectrum`](https://spectrum.ieee.org/) wrote a great article [Hash Your Way To a Better Neural Network](https://spectrum.ieee.org/tech-talk/computing/hardware/algorithms-and-hardware-for-deep-learning) about our new Deep Learning framework [`SLIDE`](https://github.com/keroro824/HashingDeepLearning). The article was authored by [David Schneider](https://spectrum.ieee.org/author/schneider-david).

### Invited Talks
* I'll be talking about my research at Jane Street Symposium, New York on Jan 13th.
* Our work *SLIDE : Training Deep Neural Networks with Large Outputs on a CPU faster than a V100-GPU* was selected for a spotlight talk at Systems for ML workshop at NeurIPS 2019. [`Video coming soon`] [`pdf`](https://arxiv.org/pdf/1903.03129.pdf) [`package`](https://github.com/keroro824/HashingDeepLearning)
* I gave a talk on 'Intro to Actor-Critic Methods and Imitation in Deep Reinforcement Learning' at Houston ML Meetup at University of Houston on Dec 7th.
* I gave a talk on 'Imitation Learning' at Schlumberger, Katy, TX on Nov 19th.
* I gave a talk about my work *Imitate like a Baby:The Key to Efficient Exploration in Deep Reinforcement Learning* at BioScience Research Collaborative (BRC) in Rice Data Science Conference on Oct 14th. [`video`](https://www.youtube.com/watch?v=BzCE1tA9QeI&list=PLcsG4X8Zn_UD-U-uOKeq6SwoIJTcf_mbd&index=15)   [`pdf`](https://tharun24.github.io/AAAI_Imitation.pdf)
