---
layout: page
published: true
---

I am a senior PhD student in the Electrical and Computer Engineering Department, Rice University. I work with [Prof. Anshumali Shrivastava](https://www.cs.rice.edu/~as143/) in the [RUSHLAB](https://rushlab.blogs.rice.edu/). My primary research area is Extreme Scale Deep Learning using Randomized Hashing methods.

I previously interned as an *Applied Scientist* at **Amazon Search**, Palo Alto from *May 2018 - Aug 2019* and again during *May 2020 - Aug 2020*. I worked on a myriad of problems like query to product prediction, super-fast reformulation for zero result queries, query-category prediction and fast approximate nearest neighbor search.

I received my Bachelor of Technology (B.Tech.) in Electrical Engineering (2011-2015) from [Indian Institute of Technology, Bombay](http://www.iitb.ac.in).

Here is my [`resume`](https://tharun24.github.io/Resume.pdf).

### Updates:
* Our paper *SOLAR: Sparse Orthogonal Learned and Random Embeddings* was accepted to **ICLR 2021**. [`pdf`](https://openreview.net/pdf?id=fw-BHZ1KjxJ)[`poster`](https://tharun24.github.io/SOLAR/SOLAR_poster.pptx)
* Our paper *Fast Processing and Querying of 170TB of Genomics Data via a Repeated And Merged BloOm Filter (RAMBO)* was accepted to **SIGMOD 2021**.
* Received the __Ken Kennedy Institute BP Fellowship__ for 2020-21.
* We presented our paper *SLIDE : In Defense of Smart Algorithms over Hardware Acceleration for Large-Scale Deep Learning Systems* at **MLSys 2020**, Austin. [`pdf`](https://arxiv.org/pdf/1903.03129.pdf) [`video`](https://slideslive.com/38922010/mlsys-workshop-on-systems-for-ml-1) [`package`](https://github.com/keroro824/HashingDeepLearning)
* We presented our paper *Extreme Classification in Log Memory using Count-Min Sketch: A Case Study of Amazon Search with 50M Products* at **NeurIPS 2019**, Vancouver. [`pdf`](https://papers.nips.cc/paper/9482-extreme-classification-in-log-memory-using-count-min-sketch-a-case-study-of-amazon-search-with-50m-products.pdf) [`poster`](https://tharun24.github.io/miscellaneous/MACH_Poster.pdf)  [`video`](https://www.youtube.com/watch?v=zHXy-AlzSxQ) [`package`](https://github.com/Tharun24/MACH/)
* Received American Society of Indian Engineers (ASIE) scholarship for 2019.
* We presented __4 papers__ in __NeurIPS 2019 workshops__. Please refer to [Publications](publications.md) for a list of all papers.  

### In the News:
* An algorithm could make CPUs a cheap way to train AI **Endgadget** [`article`](https://www.engadget.com/2020/03/03/rice-university-slide-cpu-gpu-machine-learning/)
* Deep Learning breakthrough made by Rice University scientists **ARS Technica** [`article`](https://arstechnica.com/gadgets/2019/12/mach-ai-training-linear-cost-exponential-gain/)
* SLIDE algorithm for training deep neural nets faster on CPUs than GPUs **InsideHPC** [`article`](https://insidehpc.com/2020/03/slide-algorithm-for-training-deep-neural-nets-faster-on-cpus-than-gpus/)
* Hash Your Way To a Better Neural Network **IEEE Spectrum** [`article`](https://spectrum.ieee.org/tech-talk/computing/hardware/algorithms-and-hardware-for-deep-learning).
* Deep learning rethink overcomes major obstacle in AI industry **TechXplore** [`article`](https://techxplore.com/news/2020-03-deep-rethink-major-obstacle-ai.html)
* Researchers report breakthrough in 'distributed deep learning' **TechXplore** [`article`](https://techxplore.com/news/2019-12-breakthrough-deep.html).

### Invited Talks
* Jane Street Symposium 2020, New York on Jan 13th.
* Spotlight talk at Systems for ML workshop at NeurIPS 2019 on *SLIDE : Training Deep Neural Networks with Large Outputs on a CPU faster than a V100-GPU*. [`video`](https://slideslive.com/38922010/mlsys-workshop-on-systems-for-ml-1) [`pdf`](https://arxiv.org/pdf/1903.03129.pdf) [`package`](https://github.com/keroro824/HashingDeepLearning)
* 'Intro to Actor-Critic Methods and Imitation in Deep Reinforcement Learning' at Houston ML Meetup, University of Houston on Dec 7th.
* 'Imitation Learning' at Schlumberger, Katy, TX on Nov 19th.
* *Imitate like a Baby:The Key to Efficient Exploration in Deep Reinforcement Learning* at BioScience Research Collaborative (BRC) in Rice Data Science Conference on Oct 14th. [`video`](https://www.youtube.com/watch?v=BzCE1tA9QeI&list=PLcsG4X8Zn_UD-U-uOKeq6SwoIJTcf_mbd&index=15)  [`pdf`](https://tharun24.github.io/AAAI_Imitation.pdf)
